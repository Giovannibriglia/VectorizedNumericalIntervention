{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Maximum Likelihood Estimator(MLE)   \n",
    "\n",
    "A MLE coincides with the most probable Bayesian Estimator given a uniform prior distribution on the parameters. Indeed, the maximum a posteriori estimate is the parameter $\\Theta$ that maximize the probability of $\\Theta$ given tha data, given by Bayes's theorem:\n",
    "$$\n",
    "    P(\\Theta \\mid x_1, \\dots, x_n) = \\frac{f(x_1, \\dots, x_n \\mid \\Theta) \\ P(\\Theta)}{P(x_1, \\dots, x_n)}\n",
    "$$\n",
    "\n",
    "Therefore, $\\textbf{for uniform prior distribution $P(\\Theta)$}$, the bayesian estimator coincides with the MLE.\n"
   ],
   "id": "17de735ef0958c8a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-26T14:41:00.772863Z",
     "start_time": "2024-10-26T14:40:56.528139Z"
    }
   },
   "source": [
    "# %%\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "batch_size = 10\n",
    "n_epochs = 1000\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Sample data: Assume it is generated from 10 normal distributions, each with different mean and std\n",
    "torch.manual_seed(0)\n",
    "means_true = torch.linspace(1, 10, batch_size, device=device)  # True means for each distribution\n",
    "stds_true = torch.linspace(1, 2, batch_size, device=device)  # True stds for each distribution\n",
    "data = torch.stack([torch.normal(mean, std, size=(10000,), device=device) for mean, std in zip(means_true, stds_true)])  # shape: (10, 10000)\n",
    "\n",
    "# Parameters to estimate: Mean (mu) and standard deviation (sigma) for each of the 10 distributions\n",
    "mu = torch.randn(batch_size, requires_grad=True, device=device)  # Initialize mu for 10 distributions\n",
    "sigma = torch.randn(batch_size, requires_grad=True, device=device)  # Initialize sigma for 10 distributions\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam([mu, sigma], lr=0.1)\n",
    "\n",
    "# Maximum Likelihood Estimation using Gaussian log-likelihood\n",
    "progress_bar = tqdm(range(n_epochs), desc=\"Training Progress\")\n",
    "for step in progress_bar:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Convert log(sigma) to sigma to ensure sigma is positive\n",
    "    sigma_clamped = torch.exp(sigma)\n",
    "    \n",
    "    # Negative log-likelihood of the Gaussian distribution\n",
    "    nll = -torch.mean(-0.5 * torch.log(2 * torch.pi * sigma_clamped**2).unsqueeze(1) \n",
    "                      - 0.5 * ((data - mu.unsqueeze(1))**2 / (sigma_clamped.unsqueeze(1)**2)))\n",
    "\n",
    "    # Backpropagate and optimize\n",
    "    nll.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    # Calculate RMSE between estimated parameters and true values\n",
    "    rmse_mu = torch.sqrt(torch.mean((mu - means_true) ** 2)).item()\n",
    "    rmse_sigma = torch.sqrt(torch.mean((sigma_clamped - stds_true) ** 2)).item()\n",
    "\n",
    "    # Update the tqdm description with current estimates for every step\n",
    "    progress_bar.set_description(\n",
    "        f\"Step {step+1} - NLL: {nll.item():.4f}, RMSE_mu: {rmse_mu:.4f}, RMSE_sigma: {rmse_sigma:.4f}\"\n",
    "    )\n",
    "\n",
    "print(\"\\n\")\n",
    "# Final estimated parameters\n",
    "print(f'Estimated means: {mu}')\n",
    "print(f'Estimated standard deviations: {sigma_clamped}')\n",
    "print(f'RMSE for mu: {rmse_mu:.4f}')\n",
    "print(f'RMSE for sigma: {rmse_sigma:.4f}')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1000 - NLL: 1.8015, RMSE_mu: 0.0212, RMSE_sigma: 0.0057: 100%|██████████| 1000/1000 [00:03<00:00, 297.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Estimated means: tensor([ 0.9921,  2.0002,  3.0183,  3.9970,  5.0182,  6.0056,  6.9943,  7.9591,\n",
      "         9.0311, 10.0327], device='cuda:0', requires_grad=True)\n",
      "Estimated standard deviations: tensor([1.0002, 1.1110, 1.2147, 1.3455, 1.4435, 1.5568, 1.6692, 1.7804, 1.8970,\n",
      "        1.9940], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "RMSE for mu: 0.0212\n",
      "RMSE for sigma: 0.0057\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2356626588fb79c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T14:25:49.556641Z",
     "start_time": "2024-10-24T14:25:49.525277Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shape: torch.Size([10])\n",
      "Covariance matrix shape: torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": "",
   "id": "ba9d924d56b1a14c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
